# FBID

## Objetivos
- [x] Lograr el funcionamiento de la práctica sin modificaciones
- [x] Ejecución del job de predicción con Spark Submit en vez de IntelliJ
- [ ] Dockerizar cada uno de los servicios que componen la arquitectura completa
- [ ] Desplegar el escenario completo usando docker-compose
- [ ] Desplegar el escenario completo usando kubernetes
- [ ] Desplegar el escenario completo en Google Cloud/AWS
- [ ] Entrenar el modelo con Apache Airflow

### Lograr el funcionamiento de la práctica sin modificaciones

Primero de todo se ha decidido utilizar el sistema operativo Ubuntu debido a las recomendaciones de los profesores, por lo que se deplego una maquina virtual con este sistema operativo instalado.
En dicha máquina virtual, se debe instalar la siguiente lista de programas con sus respectivas versiones:

- Intellij (jdk_1.8)
- Pyhton3 (version 3.6)
- PIP
- SBT
- MongoDB (version 4.4)
- Spark (version 3.1.2)
- Scala(version 2.12)
- Zookeeper
- Kafka (version kafka_2.12-3.0.0)

### Ejecución del job de predicción con Spark Submit
### Dockerizar cada uno de los servicios que componen la arquitectura completa
### Desplegar el escenario completo usando docker-compose
### Desplegar el escenario completo usando kubernetes
### Desplegar el escenario completo en Google Cloud/AWS
### Entrenar el modelo con Apache Airflow
